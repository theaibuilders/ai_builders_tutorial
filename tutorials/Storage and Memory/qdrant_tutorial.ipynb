{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qdrant: A Beginner's Tutorial to Vector Search\n",
    "\n",
    "Welcome to this tutorial on Qdrant, an open-source vector database and vector similarity search engine. Qdrant helps you build the next generation of AI-powered applications by providing a powerful, production-ready service to store, search, and manage vector embeddings.\n",
    "\n",
    "In this notebook, we will cover the fundamental concepts of Qdrant and walk through a practical example of building a simple semantic search engine. We'll explore:\n",
    "\n",
    "1.  **Setup and Installation**: Getting your environment ready.\n",
    "2.  **Connecting to Qdrant**: Initializing the Qdrant client.\n",
    "3.  **Creating Collections**: Setting up a space for our vectors.\n",
    "4.  **Generating and Uploading Vectors**: Preparing and storing our vector data.\n",
    "5.  **Performing Searches**: Running semantic and filtered searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, you'll need to install the necessary Python libraries. We'll use `qdrant-client` to interact with Qdrant, `sentence-transformers` to generate our vector embeddings, and `python-dotenv` to manage our API keys and environment variables.\n",
    "\n",
    "You can install them by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install qdrant-client sentence-transformers python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Environment Variables\n",
    "\n",
    "It's a best practice to manage sensitive information like API keys securely. We'll use a `.env` file to store these credentials. Create a file named `.env` in the same directory as this notebook and add the following lines:\n",
    "\n",
    "QDRANT_API_KEY=\"your_qdrant_api_key_here\"\n",
    "\n",
    "QDRANT_URL=\"your_qdrant_url_here\"\n",
    "\n",
    "For this tutorial, you can easily set up a Qdrant cloud cluster and get the above env variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key and URL from environment variables\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connecting to Qdrant\n",
    "\n",
    "The `QdrantClient` is our entry point to interacting with the Qdrant service. Qdrant can be run in different ways:\n",
    "\n",
    "- **In-memory**: Perfect for quick experiments and testing, as all data is cleared when the process finishes.\n",
    "- **On-disk storage**: A local, persistent storage option.\n",
    "- **Docker**: Running Qdrant as a standalone server.\n",
    "- **Qdrant Cloud**: A fully managed, scalable cloud solution.\n",
    "\n",
    "For simplicity, we'll use the Qdrant cloud in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Qdrant client for in-memory storage\n",
    "# client = QdrantClient(\":memory:\")\n",
    "\n",
    "# If you were connecting to Qdrant Cloud, you would use:\n",
    "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a Collection\n",
    "\n",
    "In Qdrant, a **collection** is a named set of points (vectors with a payload). Think of it as a table in a SQL database. When creating a collection, you need to define the configuration for the vectors it will store, such as their size (dimensionality) and the distance metric for similarity search.\n",
    "\n",
    "Common distance metrics include:\n",
    "- **Cosine**: Measures the angle between two vectors. Great for text embeddings.\n",
    "- **Euclidean**: The straight-line distance between two points.\n",
    "- **Dot Product**: A measure of similarity that also considers vector magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/g_b0j0n53rz5fm8yrlw3jg040000gn/T/ipykernel_48560/1209000986.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_collection = \"my_first_collection\"\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating and Uploading Vectors\n",
    "\n",
    "To perform semantic search, we need to convert our text data into numerical representations called vector embeddings. We'll use a pre-trained model from `sentence-transformers` for this task. The model `all-MiniLM-L6-v2` is a good choice for its balance of speed and quality, and it outputs vectors of size 384, matching our collection's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devon/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Let's create some sample documents\n",
    "documents = [\n",
    "    {\"id\": 1, \"text\": \"Qdrant is a vector database for building AI applications.\", \"metadata\": {\"type\": \"tech\"}},\n",
    "    {\"id\": 2, \"text\": \"The Eiffel Tower is a famous landmark in Paris, France.\", \"metadata\": {\"type\": \"travel\"}},\n",
    "    {\"id\": 3, \"text\": \"A vector database indexes vectors for easy search and retrieval.\", \"metadata\": {\"type\": \"tech\"}},\n",
    "    {\"id\": 4, \"text\": \"The Great Wall of China is one of the world's wonders.\", \"metadata\": {\"type\": \"travel\"}},\n",
    "    {\"id\": 5, \"text\": \"Artificial intelligence is transforming many industries.\", \"metadata\": {\"type\": \"tech\"}}\n",
    "]\n",
    "\n",
    "# Generate embeddings for our documents\n",
    "embeddings = model.encode([doc[\"text\"] for doc in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upserting Points\n",
    "\n",
    "Now that we have our embeddings, we'll upload them to our Qdrant collection. In Qdrant, a **point** is the central entity, consisting of a vector, a unique ID, and an optional **payload** (a JSON object for metadata). We use the `upsert` operation, which will add new points or update existing ones with the same ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=doc[\"id\"],\n",
    "            vector=embedding.tolist(),\n",
    "            payload=doc[\"metadata\"]\n",
    "        )\n",
    "        for doc, embedding in zip(documents, embeddings)\n",
    "    ],\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performing Searches\n",
    "\n",
    "### Semantic Search\n",
    "\n",
    "The core functionality of a vector database is finding the most similar vectors to a given query vector. This is semantic search. We'll take a query, encode it into a vector using the same model, and then use Qdrant to find the closest matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search Results:\n",
      "- ID: 3, Score: 0.6311\n",
      "  Text: A vector database indexes vectors for easy search and retrieval.\n",
      "- ID: 1, Score: 0.5301\n",
      "  Text: Qdrant is a vector database for building AI applications.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a vector database?\"\n",
    "query_vector = model.encode(query).tolist()\n",
    "\n",
    "search_results = client.query_points(\n",
    "    collection_name=my_collection,\n",
    "    query=query_vector,\n",
    "    limit=2,  # Return the top 2 most similar results\n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "# Map IDs to original document text so we can display it with results\n",
    "id_to_text = {doc[\"id\"]: doc[\"text\"] for doc in documents}\n",
    "\n",
    "print(\"Semantic Search Results:\")\n",
    "for result in search_results.points:\n",
    "    print(f\"- ID: {result.id}, Score: {result.score:.4f}\")\n",
    "    text = id_to_text.get(result.id)\n",
    "    if text is not None:\n",
    "        print(f\"  Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with a Filter\n",
    "\n",
    "Qdrant's real power comes from its ability to combine vector search with filtering on the payload. This allows you to narrow down your search to only the points that match certain metadata criteria. Here, we'll search for the same query but only within documents of the \"travel\" type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created payload index for 'type' (KEYWORD).\n"
     ]
    }
   ],
   "source": [
    "# Create a payload index for the string field 'type' so we can filter on it\n",
    "# Qdrant requires an index of type KEYWORD for exact-match string filters\n",
    "try:\n",
    "    client.create_payload_index(\n",
    "        collection_name=my_collection,\n",
    "        field_name=\"type\",\n",
    "        field_schema=models.PayloadSchemaType.KEYWORD,\n",
    "    )\n",
    "    print(\"Created payload index for 'type' (KEYWORD).\")\n",
    "except Exception as e:\n",
    "    # Safe to ignore if already exists and we're re-running cells\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(\"Payload index for 'type' already exists.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Search Results (type='travel'):\n",
      "- ID: 2, Score: 0.0032, Payload: {'type': 'travel'}\n",
      "  Text: The Eiffel Tower is a famous landmark in Paris, France.\n",
      "- ID: 4, Score: -0.0419, Payload: {'type': 'travel'}\n",
      "  Text: The Great Wall of China is one of the world's wonders.\n"
     ]
    }
   ],
   "source": [
    "filtered_search_results = client.query_points(\n",
    "    collection_name=my_collection,\n",
    "    query=query_vector,\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"type\",\n",
    "                match=models.MatchValue(value=\"travel\")\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=2,\n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "print(\"Filtered Search Results (type='travel'):\")\n",
    "for result in filtered_search_results.points:\n",
    "    print(f\"- ID: {result.id}, Score: {result.score:.4f}, Payload: {result.payload}\")\n",
    "    text = id_to_text.get(result.id)\n",
    "    if text is not None:\n",
    "        print(f\"  Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've successfully built a small semantic search engine using Qdrant. You've learned how to:\n",
    "\n",
    "- Set up your environment and connect to Qdrant.\n",
    "- Create collections with specific vector configurations.\n",
    "- Generate vector embeddings from text data.\n",
    "- Upsert points with vectors and metadata payloads.\n",
    "- Perform both semantic and filtered searches.\n",
    "\n",
    "This is just the beginning. From here, you can explore more advanced topics like:\n",
    "\n",
    "- **Hybrid Search**: Combining keyword-based (sparse) and semantic (dense) vectors for more accurate results.\n",
    "- **Scalability**: Using Docker or Qdrant Cloud for larger, production-level applications.\n",
    "- **Advanced Filtering**: Creating more complex filtering conditions.\n",
    "\n",
    "Happy building!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
