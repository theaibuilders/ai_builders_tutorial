<!DOCTYPE html><html lang="en" class="dark" data-astro-cid-ds6ctzq3> <head><meta charset="utf-8"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>LangChain Tutorial: From Fundamentals to Advanced RAG | AI Builders Tutorial</title><meta name="description" content="Learn AI development with comprehensive tutorials and hands-on examples."><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=Fira+Code:wght@300;400;500;600&display=swap" rel="stylesheet"><!-- Theme Script (runs before page load to prevent flash) --><script>
      // Check for saved theme preference or default to 'dark'
      const theme = localStorage.getItem('theme') || 'dark';
      document.documentElement.classList.toggle('dark', theme === 'dark');
    </script><link rel="stylesheet" href="/_astro/index.DPx-RtU2.css">
<link rel="stylesheet" href="/_astro/_slug_.DMzLkZQI.css"><script type="module" src="/_astro/hoisted.PWx6W9zp.js"></script></head> <body class="bg-light-bg dark:bg-dark-bg text-light-text dark:text-dark-text font-sans antialiased" data-astro-cid-ds6ctzq3> <!-- Main Layout Container --> <div class="flex min-h-screen" data-astro-cid-ds6ctzq3> <!-- Left Sidebar --> <aside class="w-80 flex-shrink-0 border-r border-light-border dark:border-dark-border" data-astro-cid-ds6ctzq3> <div class="h-screen flex flex-col" data-astro-cid-ryjzjgvk> <!-- Header --> <div class="flex-shrink-0 p-6 border-b border-light-border dark:border-dark-border" data-astro-cid-ryjzjgvk> <div class="flex items-center justify-between mb-4" data-astro-cid-ryjzjgvk> <h1 class="text-xl font-bold text-light-text dark:text-dark-text" data-astro-cid-ryjzjgvk>
AI Builders Tutorial
</h1> <button id="theme-toggle" class="p-2 rounded-lg bg-light-surface dark:bg-dark-surface hover:bg-light-hover dark:hover:bg-dark-hover transition-colors" onclick="toggleTheme()" aria-label="Toggle theme" data-astro-cid-ryjzjgvk> <svg class="w-5 h-5 text-light-secondary dark:text-dark-secondary" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <path class="dark:hidden" fill-rule="evenodd" d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" clip-rule="evenodd" data-astro-cid-ryjzjgvk></path> <path class="hidden dark:block" d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z" data-astro-cid-ryjzjgvk></path> </svg> </button> </div> <!-- Search Bar --> <div class="relative" id="search-container" data-astro-cid-mjrxwznw> <div class="relative" data-astro-cid-mjrxwznw> <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none" data-astro-cid-mjrxwznw> <svg class="h-4 w-4 text-light-secondary dark:text-dark-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24" data-astro-cid-mjrxwznw> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" data-astro-cid-mjrxwznw></path> </svg> </div> <input type="text" id="search-input" placeholder="Search tutorials..." class="w-full pl-10 pr-4 py-2 text-sm bg-light-surface dark:bg-dark-surface border border-light-border dark:border-dark-border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent text-light-text dark:text-dark-text placeholder-light-secondary dark:placeholder-dark-secondary" data-astro-cid-mjrxwznw> <div id="search-loading" class="absolute inset-y-0 right-0 pr-3 flex items-center hidden" data-astro-cid-mjrxwznw> <div class="animate-spin h-4 w-4 border-2 border-blue-500 border-t-transparent rounded-full" data-astro-cid-mjrxwznw></div> </div> </div> <!-- Search Results Dropdown --> <div id="search-results" class="absolute z-50 w-full mt-2 bg-light-bg dark:bg-dark-bg border border-light-border dark:border-dark-border rounded-lg shadow-lg max-h-80 overflow-y-auto hidden" data-astro-cid-mjrxwznw> <!-- Results will be populated by JavaScript --> </div> </div>   </div> <!-- Navigation Content --> <div class="flex-1 overflow-y-auto" data-astro-cid-ryjzjgvk> <nav class="p-4" data-astro-cid-ryjzjgvk> <div class="mb-6" data-astro-cid-ryjzjgvk> <!-- Section Header --> <button class="flex items-center justify-between w-full text-left p-2 rounded-lg hover:bg-light-hover dark:hover:bg-dark-hover transition-colors group" data-section="Overview" onclick="toggleSection(this)" data-astro-cid-ryjzjgvk> <span class="font-semibold text-light-text dark:text-dark-text capitalize" data-astro-cid-ryjzjgvk> Overview </span> <svg class="w-4 h-4 text-light-secondary dark:text-dark-secondary transform transition-transform group-data-[expanded]:rotate-90" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <path fill-rule="evenodd" d="M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z" clip-rule="evenodd" data-astro-cid-ryjzjgvk></path> </svg> </button> <!-- Section Files --> <div class="ml-4 mt-2 space-y-1 section-content" data-section-content="Overview" style="display: block;" data-astro-cid-ryjzjgvk> <a href="/tutorials/Overview/tutorial_overview" class="block p-2 rounded-lg text-sm transition-colors text-light-secondary dark:text-dark-secondary hover:bg-light-hover dark:hover:bg-dark-hover hover:text-light-text dark:hover:text-dark-text" data-astro-cid-ryjzjgvk> <div class="flex items-center gap-2" data-astro-cid-ryjzjgvk> <!-- File Type Icon --> <svg class="w-4 h-4 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <!-- Markdown icon -->
                        <path d="M4 3a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V5a2 2 0 00-2-2H4zm0 2h12v10H4V5zm2 2v6l2-2 2 2V7H6z" data-astro-cid-ryjzjgvk></path> </svg> <!-- File Name --> <span class="truncate" data-astro-cid-ryjzjgvk> AI Builders Tutorial Overview </span> <!-- File Extension Badge --> <span class="text-xs px-1.5 py-0.5 rounded bg-blue-500/20 text-blue-400" data-astro-cid-ryjzjgvk> md </span> </div> <!-- File Description (if available) --> <div class="mt-1 text-xs text-light-secondary dark:text-dark-secondary opacity-75 line-clamp-2" data-astro-cid-ryjzjgvk> Welcome to the AI Builders Tutorial platform! This comprehensive guide will take you through the fundamentals of building AI-powered applications using modern frameworks and tools. </div> </a> </div> </div><div class="mb-6" data-astro-cid-ryjzjgvk> <!-- Section Header --> <button class="flex items-center justify-between w-full text-left p-2 rounded-lg hover:bg-light-hover dark:hover:bg-dark-hover transition-colors group" data-section="Agent Frameworks" onclick="toggleSection(this)" data-astro-cid-ryjzjgvk> <span class="font-semibold text-light-text dark:text-dark-text capitalize" data-astro-cid-ryjzjgvk> Agent Frameworks </span> <svg class="w-4 h-4 text-light-secondary dark:text-dark-secondary transform transition-transform group-data-[expanded]:rotate-90" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <path fill-rule="evenodd" d="M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z" clip-rule="evenodd" data-astro-cid-ryjzjgvk></path> </svg> </button> <!-- Section Files --> <div class="ml-4 mt-2 space-y-1 section-content" data-section-content="Agent Frameworks" style="display: block;" data-astro-cid-ryjzjgvk> <a href="/tutorials/Agent Frameworks/langchain" class="block p-2 rounded-lg text-sm transition-colors bg-blue-500/10 text-blue-400 border-l-2 border-blue-400" data-astro-cid-ryjzjgvk> <div class="flex items-center gap-2" data-astro-cid-ryjzjgvk> <!-- File Type Icon --> <svg class="w-4 h-4 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <!-- Notebook icon -->
                        <path d="M4 3a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V5a2 2 0 00-2-2H4zm0 2h12v10H4V5zm2 2a1 1 0 000 2h8a1 1 0 100-2H6zm0 3a1 1 0 000 2h8a1 1 0 100-2H6zm0 3a1 1 0 000 2h8a1 1 0 100-2H6z" data-astro-cid-ryjzjgvk></path> </svg> <!-- File Name --> <span class="truncate" data-astro-cid-ryjzjgvk> LangChain Tutorial: From Fundamentals to Advanced RAG </span> <!-- File Extension Badge --> <span class="text-xs px-1.5 py-0.5 rounded bg-orange-500/20 text-orange-400" data-astro-cid-ryjzjgvk> ipynb </span> </div> <!-- File Description (if available) --> <div class="mt-1 text-xs text-light-secondary dark:text-dark-secondary opacity-75 line-clamp-2" data-astro-cid-ryjzjgvk> This tutorial provides a comprehensive overview of LangChain, covering the essential concepts from basic setup to building a sophisticated Retrieval-Augmented Generation (RAG) system. </div> </a><a href="/tutorials/Agent Frameworks/llamaindex" class="block p-2 rounded-lg text-sm transition-colors text-light-secondary dark:text-dark-secondary hover:bg-light-hover dark:hover:bg-dark-hover hover:text-light-text dark:hover:text-dark-text" data-astro-cid-ryjzjgvk> <div class="flex items-center gap-2" data-astro-cid-ryjzjgvk> <!-- File Type Icon --> <svg class="w-4 h-4 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20" data-astro-cid-ryjzjgvk> <!-- Markdown icon -->
                        <path d="M4 3a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V5a2 2 0 00-2-2H4zm0 2h12v10H4V5zm2 2v6l2-2 2 2V7H6z" data-astro-cid-ryjzjgvk></path> </svg> <!-- File Name --> <span class="truncate" data-astro-cid-ryjzjgvk> Getting Started with LlamaIndex </span> <!-- File Extension Badge --> <span class="text-xs px-1.5 py-0.5 rounded bg-blue-500/20 text-blue-400" data-astro-cid-ryjzjgvk> md </span> </div> <!-- File Description (if available) --> <div class="mt-1 text-xs text-light-secondary dark:text-dark-secondary opacity-75 line-clamp-2" data-astro-cid-ryjzjgvk> LlamaIndex is a powerful framework for building Retrieval-Augmented Generation (RAG) applications. This tutorial will guide you through the fundamentals of LlamaIndex and show you how to build your first RAG application. </div> </a> </div> </div> </nav> </div> </div>   </aside> <!-- Main Content Area --> <main class="flex-1 min-w-0" data-astro-cid-ds6ctzq3> <div class="flex" data-astro-cid-ds6ctzq3> <!-- Tutorial Content --> <div class="flex-1 min-w-0" data-astro-cid-ds6ctzq3> <div class="h-screen overflow-y-auto"> <div class="max-w-4xl mx-auto p-8"> <!-- Tutorial Header --> <header class="mb-8"> <h1 class="text-4xl font-bold text-light-text dark:text-dark-text mb-2"> LangChain Tutorial: From Fundamentals to Advanced RAG </h1> <p class="text-lg text-light-secondary dark:text-dark-secondary mb-4"> This tutorial provides a comprehensive overview of LangChain, covering the essential concepts from basic setup to building a sophisticated Retrieval-Augmented Generation (RAG) system. </p> <!-- Metadata --> <div class="flex items-center gap-6 text-sm text-light-secondary dark:text-dark-secondary"> <div class="flex items-center gap-2"> <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"> <path fill-rule="evenodd" d="M10 9a3 3 0 100-6 3 3 0 000 6zm-7 9a7 7 0 1114 0H3z" clip-rule="evenodd"></path> </svg> <span>AI Builders Team</span> </div> <div class="flex items-center gap-2"> <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"> <path fill-rule="evenodd" d="M6 2a1 1 0 00-1 1v1H4a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2h-1V3a1 1 0 10-2 0v1H7V3a1 1 0 00-1-1zm0 5a1 1 0 000 2h8a1 1 0 100-2H6z" clip-rule="evenodd"></path> </svg> <span>Last updated: 7/29/2025</span> </div> <div class="flex items-center gap-2"> <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"> <path d="M4 3a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V5a2 2 0 00-2-2H4zm0 2h12v10H4V5zm2 2a1 1 0 000 2h8a1 1 0 100-2H6zm0 3a1 1 0 000 2h8a1 1 0 100-2H6zm0 3a1 1 0 000 2h8a1 1 0 100-2H6z"></path> </svg> <span class="px-2 py-1 rounded text-xs bg-orange-500/20 text-orange-400"> Jupyter Notebook </span> </div> <div class="flex items-center gap-2"> <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"> <path fill-rule="evenodd" d="M3 6a3 3 0 013-3h10a1 1 0 01.8 1.6L14.25 8l2.55 3.4A1 1 0 0116 13H6a1 1 0 00-1 1v3a1 1 0 11-2 0V6z" clip-rule="evenodd"></path> </svg> <span class="px-2 py-1 rounded text-xs capitalize bg-green-500/20 text-green-400"> beginner </span> </div> </div> <div class="flex items-center gap-2 mt-3"> <svg class="w-4 h-4 text-light-secondary dark:text-dark-secondary" fill="currentColor" viewBox="0 0 20 20"> <path fill-rule="evenodd" d="M17.707 9.293a1 1 0 010 1.414l-7 7a1 1 0 01-1.414 0l-7-7A.997.997 0 012 10V5a3 3 0 013-3h5c.256 0 .512.098.707.293l7 7zM5 6a1 1 0 100-2 1 1 0 000 2z" clip-rule="evenodd"></path> </svg> <div class="flex flex-wrap gap-2"> <span class="px-2 py-1 bg-light-surface dark:bg-dark-surface text-light-secondary dark:text-dark-secondary text-xs rounded"> jupyter </span><span class="px-2 py-1 bg-light-surface dark:bg-dark-surface text-light-secondary dark:text-dark-secondary text-xs rounded"> tutorial </span> </div> </div> </header> <!-- Tutorial Content --> <div class="tutorial-content"> <div>
    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-0">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <h3 class="text-xl font-semibold mb-4 mt-8 text-white border-b border-gray-700 pb-2"><strong class="font-semibold text-white">LangChain Tutorial: From Fundamentals to Advanced RAG</strong></h3></p><p class="mb-4 text-gray-300 leading-relaxed">This tutorial provides a comprehensive overview of LangChain, covering the essential concepts from basic setup to building a sophisticated Retrieval-Augmented Generation (RAG) system.
      </div>
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-1">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <h3 class="text-xl font-semibold mb-4 mt-8 text-white border-b border-gray-700 pb-2"><strong class="font-semibold text-white">1. Introduction and Setup</strong></h3></p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">What is LangChain?</strong></p><p class="mb-4 text-gray-300 leading-relaxed">LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies the entire lifecycle of LLM application development, including development, productionization, and deployment.</p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">Core Concepts:</strong></p><p class="mb-4 text-gray-300 leading-relaxed"><ul class="list-disc list-inside mb-4 space-y-1"><li class="mb-2 text-gray-300"><strong class="font-semibold text-white">LangChain Expression Language (LCEL):</strong> A declarative way to compose chains, offering features like streaming, batching, and async support. The <code class="bg-gray-800/60 text-blue-300 px-2 py-1 rounded text-sm font-mono">|</code> (pipe) operator is central to LCEL, allowing you to chain components together.</li>
<li class="mb-2 text-gray-300"><strong class="font-semibold text-white">Components:</strong> LangChain provides modular components for building applications, including:</li>
<p class="mb-4 text-gray-300 leading-relaxed">    * <strong class="font-semibold text-white">Models:</strong> Interfaces to various language models (e.g., OpenAI, Anthropic, Google).</p>
<p class="mb-4 text-gray-300 leading-relaxed">    * <strong class="font-semibold text-white">Prompts:</strong> Templates for generating prompts for LLMs.</p>
<p class="mb-4 text-gray-300 leading-relaxed">    * <strong class="font-semibold text-white">Output Parsers:</strong> Tools to structure the output from LLMs.</p>
<li class="mb-2 text-gray-300"><strong class="font-semibold text-white">Retrieval-Augmented Generation (RAG):</strong> A powerful technique to connect LLMs to external data sources, enhancing their knowledge and providing more accurate, up-to-date responses.</li></ul></p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">Installation</strong></p><p class="mb-4 text-gray-300 leading-relaxed">First, let's install the necessary packages.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-2">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="# Install core LangChain and provider-specific packages
!pip install langchain langchain-core langchain-community langchain-openai langchain-chroma faiss-cpu pypdf sentence-transformers tiktoken -q

# Install environment management and web request libraries
!pip install python-dotenv requests beautifulsoup4 -q"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Install</span> core <span class="text-yellow-300">LangChain</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>and</span> provider-specific packages !<span class="text-cyan-400">pip</span> <span class="text-cyan-400">install</span> langchain langchain-core langchain-community langchain-openai langchain-chroma faiss-cpu pypdf sentence-transformers tiktoken -q # <span class="text-yellow-300">Install</span> environment management <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>and</span> web request libraries !<span class="text-cyan-400">pip</span> <span class="text-cyan-400">install</span> python-dotenv requests beautifulsoup4 -q</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-3">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Environment Setup</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Configure your API keys. It's recommended to use environment variables for security.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-4">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="import os
import getpass
from dotenv import load_dotenv

# Load environment variables from a .env file if it exists
load_dotenv()

# Set up your OpenAI API key
if &quot;OPENAI_API_KEY&quot; not in os.environ:
    os.environ[&quot;OPENAI_API_KEY&quot;] = getpass.getpass(&quot;Enter your OpenAI API key: &quot;)

print(&quot;âœ… API keys configured!&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> os <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> getpass <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> dotenv <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> load_dotenv <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Load</span> environment variables <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> a .env file <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>if</span> it exists <span class="text-blue-400">load_dotenv</span>() # <span class="text-yellow-300">Set</span> up your <span class="text-yellow-300">OpenAI</span> <span class="text-yellow-300">API</span> key <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>if</span> <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">OPENAI_API_KEY</span>"</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>not</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>in</span> os.environ: os.environ[<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">OPENAI_API_KEY</span>"</span>] = getpass.<span class="text-blue-400">getpass</span>(<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Enter</span> your <span class="text-yellow-300">OpenAI</span> <span class="text-yellow-300">API</span> key: "</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"âœ… <span class="text-yellow-300">API</span> keys configured!"</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-5">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <h3 class="text-xl font-semibold mb-4 mt-8 text-white border-b border-gray-700 pb-2"><strong class="font-semibold text-white">2. Building Your First Chain with LCEL</strong></h3></p><p class="mb-4 text-gray-300 leading-relaxed">A "chain" in LangChain is a sequence of calls to components. We'll use the LangChain Expression Language (LCEL) to build a simple chain.</p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">Initialize the Model</strong></p><p class="mb-4 text-gray-300 leading-relaxed">We'll start by initializing a chat model.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-6">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain.chat_models import init_chat_model

# Initialize a chat model from OpenAI
model = init_chat_model(&quot;gpt-4o-mini&quot;, model_provider=&quot;openai&quot;, temperature=0.7)

print(f&quot;âœ… Initialized model: {model.__class__.__name__}&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain.chat_models <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> init_chat_model <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Initialize</span> a chat model <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> <span class="text-yellow-300">OpenAI</span> model = <span class="text-blue-400">init_chat_model</span>(<span class="text-green-<span class="text-yellow-400">400</span>">"gpt-4o-mini"</span>, model_provider=<span class="text-green-<span class="text-yellow-400">400</span>">"openai"</span>, temperature=<span class="text-yellow-400">0.7</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"âœ… <span class="text-yellow-300">Initialized</span> model: {model.<span class="text-magenta-400">__class__</span>.<span class="text-magenta-400">__name__</span>}"</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-7">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Work with Prompt Templates</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Prompt templates allow you to create reusable and parameterized prompts.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-8">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Create a prompt template
prompt_template = ChatPromptTemplate.from_messages([
    (&quot;system&quot;, &quot;You are an expert in {expertise}.&quot;),
    (&quot;human&quot;, &quot;Explain {topic} in a simple and concise way.&quot;)
])

# Create a simple chain using LCEL
# The chain will:
# 1. Take user input for &#39;expertise&#39; and &#39;topic&#39;.
# 2. Format the prompt using the prompt_template.
# 3. Pass the formatted prompt to the model.
# 4. Parse the model&#39;s output to a string.
simple_chain = prompt_template | model | StrOutputParser()

# Invoke the chain
response = simple_chain.invoke({
    &quot;expertise&quot;: &quot;physics&quot;,
    &quot;topic&quot;: &quot;quantum entanglement&quot;
})

print(response)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_core.prompts <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">ChatPromptTemplate</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_core.output_parsers <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">StrOutputParser</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Create</span> a prompt template prompt_template = <span class="text-yellow-300">ChatPromptTemplate</span>.<span class="text-blue-400">from_messages</span>([ (<span class="text-green-<span class="text-yellow-400">400</span>">"system"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">You</span> are an expert <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">in</span> {expertise}."</span>), (<span class="text-green-<span class="text-yellow-400">400</span>">"human"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Explain</span> {topic} <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">in</span> a simple <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">and</span> concise way."</span>) ]) # <span class="text-yellow-300">Create</span> a simple chain using <span class="text-yellow-300">LCEL</span> # <span class="text-yellow-300">The</span> chain will: # <span class="text-yellow-400">1</span>. <span class="text-yellow-300">Take</span> user <span class="text-cyan-400">input</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> <span class="text-green-<span class="text-yellow-400">400</span>">'expertise'</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>and</span> <span class="text-green-<span class="text-yellow-400">400</span>">'topic'</span>. # <span class="text-yellow-400">2</span>. <span class="text-yellow-300">Format</span> the prompt using the prompt_template. # <span class="text-yellow-400">3</span>. <span class="text-yellow-300">Pass</span> the formatted prompt to the model. # <span class="text-yellow-400">4</span>. <span class="text-yellow-300">Parse</span> the model's output to a string. simple_chain = prompt_template | model | <span class="text-blue-400"><span class="text-yellow-300">StrOutputParser</span></span>() # <span class="text-yellow-300">Invoke</span> the chain response = simple_chain.<span class="text-blue-400">invoke</span>({ <span class="text-green-<span class="text-yellow-400">400</span>">"expertise"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"physics"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"topic"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"quantum entanglement"</span> }) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(response)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-9">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Streaming Responses</strong></p><p class="mb-4 text-gray-300 leading-relaxed">For a better user experience, you can stream the model's response as it's generated.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-10">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="print(&quot;ðŸŒŠ Streaming response:&quot;)
for chunk in simple_chain.stream({
    &quot;expertise&quot;: &quot;culinary arts&quot;,
    &quot;topic&quot;: &quot;the Maillard reaction&quot;
}):
    print(chunk, end=&quot;&quot;, flush=True)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"ðŸŒŠ <span class="text-yellow-300">Streaming</span> response:"</span>) <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> chunk <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>in</span> simple_chain.<span class="text-blue-400">stream</span>({ <span class="text-green-<span class="text-yellow-400">400</span>">"expertise"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"culinary arts"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"topic"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"the <span class="text-yellow-300">Maillard</span> reaction"</span> }): <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(chunk, end=<span class="text-green-<span class="text-yellow-400">400</span>">""</span>, flush=<span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>><span class="text-yellow-300">True</span></span>)</code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-11">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <h3 class="text-xl font-semibold mb-4 mt-8 text-white border-b border-gray-700 pb-2"><strong class="font-semibold text-white">3. Structured Output and Advanced Chains</strong></h3></p><p class="mb-4 text-gray-300 leading-relaxed">LangChain can parse model outputs into structured formats and build more complex, conditional chains.</p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">Pydantic Output Parser</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Use Pydantic models to define the desired output structure.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-12">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from typing import List
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser

# Define a Pydantic model for structured output
class Recipe(BaseModel):
    name: str = Field(description=&quot;The name of the recipe&quot;)
    ingredients: List[str] = Field(description=&quot;A list of ingredients&quot;)
    steps: List[str] = Field(description=&quot;The steps to prepare the recipe&quot;)

# Create a Pydantic output parser
pydantic_parser = PydanticOutputParser(pydantic_object=Recipe)

# Create a prompt that includes format instructions
structured_prompt = ChatPromptTemplate.from_messages([
    (&quot;system&quot;, &quot;You are a world-class chef. Generate a recipe based on the user&#39;s request and format it as requested.&quot;),
    (&quot;human&quot;, &quot;I want a simple recipe for {dish}.\n\n{format_instructions}&quot;)
])

# Create the structured output chain
structured_chain = structured_prompt | model | pydantic_parser

# Invoke the chain
recipe_request = {
    &quot;dish&quot;: &quot;scrambled eggs&quot;,
    &quot;format_instructions&quot;: pydantic_parser.get_format_instructions()
}
recipe_output = structured_chain.invoke(recipe_request)

print(f&quot;Recipe for: {recipe_output.name}&quot;)
print(&quot;\nIngredients:&quot;)
for ingredient in recipe_output.ingredients:
    print(f&quot;- {ingredient}&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> typing <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">List</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> pydantic <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">BaseModel</span>, <span class="text-yellow-300">Field</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_core.output_parsers <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">PydanticOutputParser</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Define</span> a <span class="text-yellow-300">Pydantic</span> model <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> structured output <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>class</span> <span class="text-blue-400"><span class="text-yellow-300">Recipe</span></span>(<span class="text-yellow-300">BaseModel</span>): name: <span class="text-cyan-400">str</span> = <span class="text-blue-400"><span class="text-yellow-300">Field</span></span>(description=<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">The</span> name of the recipe"</span>) ingredients: <span class="text-yellow-300">List</span>[<span class="text-cyan-400">str</span>] = <span class="text-blue-400"><span class="text-yellow-300">Field</span></span>(description=<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">A</span> <span class="text-cyan-400">list</span> of ingredients"</span>) steps: <span class="text-yellow-300">List</span>[<span class="text-cyan-400">str</span>] = <span class="text-blue-400"><span class="text-yellow-300">Field</span></span>(description=<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">The</span> steps to prepare the recipe"</span>) # <span class="text-yellow-300">Create</span> a <span class="text-yellow-300">Pydantic</span> output parser pydantic_parser = <span class="text-blue-400"><span class="text-yellow-300">PydanticOutputParser</span></span>(pydantic_object=<span class="text-yellow-300">Recipe</span>) # <span class="text-yellow-300">Create</span> a prompt that includes format instructions structured_prompt = <span class="text-yellow-300">ChatPromptTemplate</span>.<span class="text-blue-400">from_messages</span>([ (<span class="text-green-<span class="text-yellow-400">400</span>">"system"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">You</span> are a world-<span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">class</span> chef. <span class="text-yellow-300">Generate</span> a recipe based on the user's request <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">and</span> format it <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">as</span> requested."</span>), (<span class="text-green-<span class="text-yellow-400">400</span>">"human"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">I</span> want a simple recipe <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">for</span> {dish}.\n\n{format_instructions}"</span>) ]) # <span class="text-yellow-300">Create</span> the structured output chain structured_chain = structured_prompt | model | pydantic_parser # <span class="text-yellow-300">Invoke</span> the chain recipe_request = { <span class="text-green-<span class="text-yellow-400">400</span>">"dish"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"scrambled eggs"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"format_instructions"</span>: pydantic_parser.<span class="text-blue-400">get_format_instructions</span>() } recipe_output = structured_chain.<span class="text-blue-400">invoke</span>(recipe_request) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Recipe</span> <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">for</span>: {recipe_output.name}"</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"\nIngredients:"</span>) <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> ingredient <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>in</span> recipe_output.ingredients: <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"- {ingredient}"</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-13">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Conditional Chains with <code class="bg-gray-800/60 text-blue-300 px-2 py-1 rounded text-sm font-mono">RunnableBranch</code></strong></p><p class="mb-4 text-gray-300 leading-relaxed">Create dynamic chains that change their behavior based on input conditions.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-14">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain_core.runnables import RunnableBranch

# Define different prompts for different levels
beginner_prompt = ChatPromptTemplate.from_template(&quot;Explain {topic} to a complete beginner.&quot;)
expert_prompt = ChatPromptTemplate.from_template(&quot;Provide a detailed, technical explanation of {topic}.&quot;)

# Create a conditional chain using RunnableBranch
# This chain checks the &#39;level&#39; input and routes to the appropriate prompt
conditional_chain = (
    RunnableBranch(
        (lambda x: x.get(&quot;level&quot;) == &quot;expert&quot;, expert_prompt),
        beginner_prompt  # Default prompt
    )
    | model
    | StrOutputParser()
)

# Test the beginner path
beginner_response = conditional_chain.invoke({&quot;topic&quot;: &quot;black holes&quot;, &quot;level&quot;: &quot;beginner&quot;})
print(&quot;--- Beginner Explanation ---&quot;)
print(beginner_response)

# Test the expert path
expert_response = conditional_chain.invoke({&quot;topic&quot;: &quot;black holes&quot;, &quot;level&quot;: &quot;expert&quot;})
print(&quot;\n--- Expert Explanation ---&quot;)
print(expert_response)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_core.runnables <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">RunnableBranch</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Define</span> different prompts <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> different levels beginner_prompt = <span class="text-yellow-300">ChatPromptTemplate</span>.<span class="text-blue-400">from_template</span>(<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Explain</span> {topic} to a complete beginner."</span>) expert_prompt = <span class="text-yellow-300">ChatPromptTemplate</span>.<span class="text-blue-400">from_template</span>(<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Provide</span> a detailed, technical explanation of {topic}."</span>) # <span class="text-yellow-300">Create</span> a conditional chain using <span class="text-yellow-300">RunnableBranch</span> # <span class="text-yellow-300">This</span> chain checks the <span class="text-green-<span class="text-yellow-400">400</span>">'level'</span> <span class="text-cyan-400">input</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>and</span> routes to the appropriate prompt conditional_chain = ( <span class="text-blue-400"><span class="text-yellow-300">RunnableBranch</span></span>( (<span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>lambda</span> x: x.<span class="text-blue-400">get</span>(<span class="text-green-<span class="text-yellow-400">400</span>">"level"</span>) == <span class="text-green-<span class="text-yellow-400">400</span>">"expert"</span>, expert_prompt), beginner_prompt # <span class="text-yellow-300">Default</span> prompt ) | model | <span class="text-blue-400"><span class="text-yellow-300">StrOutputParser</span></span>() ) # <span class="text-yellow-300">Test</span> the beginner path beginner_response = conditional_chain.<span class="text-blue-400">invoke</span>({<span class="text-green-<span class="text-yellow-400">400</span>">"topic"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"black holes"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"level"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"beginner"</span>}) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"--- <span class="text-yellow-300">Beginner</span> <span class="text-yellow-300">Explanation</span> ---"</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(beginner_response) # <span class="text-yellow-300">Test</span> the expert path expert_response = conditional_chain.<span class="text-blue-400">invoke</span>({<span class="text-green-<span class="text-yellow-400">400</span>">"topic"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"black holes"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"level"</span>: <span class="text-green-<span class="text-yellow-400">400</span>">"expert"</span>}) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"\n--- <span class="text-yellow-300">Expert</span> <span class="text-yellow-300">Explanation</span> ---"</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(expert_response)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-15">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <h3 class="text-xl font-semibold mb-4 mt-8 text-white border-b border-gray-700 pb-2"><strong class="font-semibold text-white">4. Retrieval-Augmented Generation (RAG)</strong></h3></p><p class="mb-4 text-gray-300 leading-relaxed">RAG connects your LLM to external data, allowing it to answer questions about information it wasn't trained on.</p><p class="mb-4 text-gray-300 leading-relaxed"><strong class="font-semibold text-white">Step 1: Document Loading and Splitting</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Load data from a source (like a website) and split it into smaller chunks for processing.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-16">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Load documents from a web page
loader = WebBaseLoader(&quot;https://python.langchain.com/docs/modules/model_io/prompts/&quot;)
docs = loader.load()

# Initialize a text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)

# Split the documents into chunks
splits = text_splitter.split_documents(docs)

print(f&quot;Loaded {len(docs)} documents and split them into {len(splits)} chunks.&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_community.document_loaders <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">WebBaseLoader</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_text_splitters <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">RecursiveCharacterTextSplitter</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Load</span> documents <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> a web page loader = <span class="text-blue-400"><span class="text-yellow-300">WebBaseLoader</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"https://python.langchain.com/docs/modules/model_io/prompts/"</span>) docs = loader.<span class="text-blue-400">load</span>() # <span class="text-yellow-300">Initialize</span> a text splitter text_splitter = <span class="text-blue-400"><span class="text-yellow-300">RecursiveCharacterTextSplitter</span></span>(chunk_size=<span class="text-yellow-400">500</span>, chunk_overlap=<span class="text-yellow-400">50</span>) # <span class="text-yellow-300">Split</span> the documents into chunks splits = text_splitter.<span class="text-blue-400">split_documents</span>(docs) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Loaded</span> {<span class="text-blue-400"><span class="text-cyan-400">len</span></span>(docs)} documents <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">and</span> split them into {<span class="text-blue-400"><span class="text-cyan-400">len</span></span>(splits)} chunks."</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-17">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Step 2: Embeddings and Vector Stores</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Convert the text chunks into numerical representations (embeddings) and store them in a vector database for efficient searching.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-18">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# Initialize OpenAI embeddings
embeddings = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)

# Create a Chroma vector store from the document splits
vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)

print(&quot;âœ… Vector store created.&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_openai <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">OpenAIEmbeddings</span> <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_chroma <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">Chroma</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Initialize</span> <span class="text-yellow-300">OpenAI</span> embeddings embeddings = <span class="text-blue-400"><span class="text-yellow-300">OpenAIEmbeddings</span></span>(model=<span class="text-green-<span class="text-yellow-400">400</span>">"text-embedding-<span class="text-yellow-400">3</span>-small"</span>) # <span class="text-yellow-300">Create</span> a <span class="text-yellow-300">Chroma</span> vector store <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> the document splits vectorstore = <span class="text-yellow-300">Chroma</span>.<span class="text-blue-400">from_documents</span>(documents=splits, embedding=embeddings) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(<span class="text-green-<span class="text-yellow-400">400</span>">"âœ… <span class="text-yellow-300">Vector</span> store created."</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-19">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Step 3: Creating a Retriever</strong></p><p class="mb-4 text-gray-300 leading-relaxed">A retriever is responsible for finding the most relevant document chunks based on a user's query.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-20">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="# Create a retriever from the vector store
retriever = vectorstore.as_retriever(search_kwargs={&quot;k&quot;: 3})

# Test the retriever
query = &quot;What are prompt templates?&quot;
retrieved_docs = retriever.invoke(query)

print(f&quot;Retrieved {len(retrieved_docs)} documents for the query: &#39;{query}&#39;&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Create</span> a retriever <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> the vector store retriever = vectorstore.<span class="text-blue-400">as_retriever</span>(search_kwargs={<span class="text-green-<span class="text-yellow-400">400</span>">"k"</span>: <span class="text-yellow-400">3</span>}) # <span class="text-yellow-300">Test</span> the retriever query = <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">What</span> are prompt templates?"</span> retrieved_docs = retriever.<span class="text-blue-400">invoke</span>(query) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">Retrieved</span> {<span class="text-blue-400"><span class="text-cyan-400">len</span></span>(retrieved_docs)} documents <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">for</span> the query: '{query}'"</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  

    <div class="notebook-cell markdown-cell mb-8" data-cell-id="cell-21">
      <div class="cell-content prose prose-dark dark:prose-dark max-w-none">
        <strong class="font-semibold text-white">Step 4: Building the RAG Chain</strong></p><p class="mb-4 text-gray-300 leading-relaxed">Now, let's combine the retriever with a prompt and the LLM to create a complete RAG chain.
      </div>
    </div>
  

    <div class="notebook-cell code-cell mb-8" data-cell-id="cell-22">
      <div class="code-block relative bg-gray-900/30 border border-gray-700 rounded-lg overflow-hidden">
        <div class="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-b border-gray-700">
          <span class="text-xs text-gray-400 font-mono">Python</span>
          <copy-button class="copy-btn" data-content="from langchain_core.runnables import RunnablePassthrough

# Define a RAG prompt template
rag_prompt = ChatPromptTemplate.from_messages([
    (&quot;system&quot;, &quot;You are a helpful assistant. Use the following context to answer the user&#39;s question.\n\nContext:\n{context}&quot;),
    (&quot;human&quot;, &quot;{question}&quot;)
])

# Helper function to format the retrieved documents
def format_docs(docs):
    return &quot;\n\n&quot;.join(doc.page_content for doc in docs)

# Create the RAG chain
rag_chain = (
    {&quot;context&quot;: retriever | format_docs, &quot;question&quot;: RunnablePassthrough()}
    | rag_prompt
    | model
    | StrOutputParser()
)

# Test the RAG chain
rag_question = &quot;How can I use few-shot examples in my prompts?&quot;
rag_answer = rag_chain.invoke(rag_question)

print(f&quot;\nâ“ Question: {rag_question}&quot;)
print(f&quot;ðŸŽ¯ Answer: {rag_answer}&quot;)"></copy-button>
        </div>
        <div class="code-content p-4 overflow-x-auto">
          <pre class="language-python text-sm"><code><span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>from</span> langchain_core.runnables <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>import</span> <span class="text-yellow-300">RunnablePassthrough</span> <span class="text-gray-<span class="text-yellow-400">500</span> italic"># <span class="text-yellow-300">Define</span> a <span class="text-yellow-300">RAG</span> prompt template rag_prompt = <span class="text-yellow-300">ChatPromptTemplate</span>.<span class="text-blue-400">from_messages</span>([ (<span class="text-green-<span class="text-yellow-400">400</span>">"system"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">You</span> are a helpful assistant. <span class="text-yellow-300">Use</span> the following context to answer the user's question.\n\nContext:\n{context}"</span>), (<span class="text-green-<span class="text-yellow-400">400</span>">"human"</span>, <span class="text-green-<span class="text-yellow-400">400</span>">"{question}"</span>) ]) # <span class="text-yellow-300">Helper</span> function to format the retrieved documents <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>def</span> <span class="text-blue-400">format_docs</span>(docs): <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>return</span> <span class="text-green-<span class="text-yellow-400">400</span>">"\n\n"</span>.<span class="text-blue-400">join</span>(doc.page_content <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>for</span> doc <span class=<span class="text-green-<span class="text-yellow-400">400</span>">"text-purple-<span class="text-yellow-400">400</span> font-semibold"</span>>in</span> docs) # <span class="text-yellow-300">Create</span> the <span class="text-yellow-300">RAG</span> chain rag_chain = ( {<span class="text-green-<span class="text-yellow-400">400</span>">"context"</span>: retriever | format_docs, <span class="text-green-<span class="text-yellow-400">400</span>">"question"</span>: <span class="text-blue-400"><span class="text-yellow-300">RunnablePassthrough</span></span>()} | rag_prompt | model | <span class="text-blue-400"><span class="text-yellow-300">StrOutputParser</span></span>() ) # <span class="text-yellow-300">Test</span> the <span class="text-yellow-300">RAG</span> chain rag_question = <span class="text-green-<span class="text-yellow-400">400</span>">"<span class="text-yellow-300">How</span> can <span class="text-yellow-300">I</span> use few-shot examples <span class="</span>text-purple-<span class="text-yellow-400">400</span> font-semibold<span class="text-green-<span class="text-yellow-400">400</span>">">in</span> my prompts?"</span> rag_answer = rag_chain.<span class="text-blue-400">invoke</span>(rag_question) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"\nâ“ <span class="text-yellow-300">Question</span>: {rag_question}"</span>) <span class="text-blue-400"><span class="text-cyan-400">print</span></span>(f<span class="text-green-<span class="text-yellow-400">400</span>">"ðŸŽ¯ <span class="text-yellow-300">Answer</span>: {rag_answer}"</span>)</span></code></pre>
        </div>
      </div>
      
    </div>
  </div> </div> </div> </div> <!-- Copy Button Component --> <copy-button class="hidden"> <button class="px-3 py-1 bg-light-surface dark:bg-dark-surface hover:bg-light-hover dark:hover:bg-dark-hover border border-light-border dark:border-dark-border rounded text-xs text-light-secondary dark:text-dark-secondary transition-colors">
Copy
</button> </copy-button>  </div> <!-- Right Sidebar (On This Page) --> <aside class="w-64 flex-shrink-0 border-l border-light-border dark:border-dark-border" data-astro-cid-ds6ctzq3> <div class="h-screen overflow-y-auto p-6" data-astro-cid-zujyv34g> <div class="sticky top-0 bg-light-bg dark:bg-dark-bg" data-astro-cid-zujyv34g> <h2 class="text-sm font-semibold text-light-text dark:text-dark-text mb-4 pb-2 border-b border-light-border dark:border-dark-border" data-astro-cid-zujyv34g>
On This Page
</h2> </div> <nav class="space-y-1" data-astro-cid-zujyv34g> <a href="#langchain-tutorial-from-fundamentals-to-advanced-rag" class="block py-1 text-sm transition-colors hover:text-light-text dark:hover:text-dark-text text-light-secondary dark:text-dark-secondary pl-4" data-heading-link="langchain-tutorial-from-fundamentals-to-advanced-rag" data-astro-cid-zujyv34g> **LangChain Tutorial: From Fundamentals to Advanced RAG** </a><a href="#1-introduction-and-setup" class="block py-1 text-sm transition-colors hover:text-light-text dark:hover:text-dark-text text-light-secondary dark:text-dark-secondary pl-4" data-heading-link="1-introduction-and-setup" data-astro-cid-zujyv34g> **1. Introduction and Setup** </a><a href="#2-building-your-first-chain-with-lcel" class="block py-1 text-sm transition-colors hover:text-light-text dark:hover:text-dark-text text-light-secondary dark:text-dark-secondary pl-4" data-heading-link="2-building-your-first-chain-with-lcel" data-astro-cid-zujyv34g> **2. Building Your First Chain with LCEL** </a><a href="#3-structured-output-and-advanced-chains" class="block py-1 text-sm transition-colors hover:text-light-text dark:hover:text-dark-text text-light-secondary dark:text-dark-secondary pl-4" data-heading-link="3-structured-output-and-advanced-chains" data-astro-cid-zujyv34g> **3. Structured Output and Advanced Chains** </a><a href="#4-retrieval-augmented-generation-rag" class="block py-1 text-sm transition-colors hover:text-light-text dark:hover:text-dark-text text-light-secondary dark:text-dark-secondary pl-4" data-heading-link="4-retrieval-augmented-generation-rag" data-astro-cid-zujyv34g> **4. Retrieval-Augmented Generation (RAG)** </a> </nav> </div>   </aside> </div> </main> </div> <!-- Theme Toggle Script -->  <!-- Copy to Clipboard Script -->  </body> </html> 